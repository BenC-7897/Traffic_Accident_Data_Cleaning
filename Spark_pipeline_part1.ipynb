{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de94482-13de-4741-aff1-1c957f594676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Import the pandas library for data manipulation and analysis\n",
    "\n",
    "# Load the dataset from a CSV file into a pandas DataFrame\n",
    "a_df = pd.read_csv(\"combined_collisions_v3.csv\")\n",
    "\n",
    "# Save the DataFrame as a Parquet file for efficient storage and faster I/O\n",
    "a_df.to_parquet(\"combined_collisions_v3.parquet\", engine=\"pyarrow\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4d8f772-fe5c-4d98-87c0-5f1ddeb079e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 Accident_Index  Location_Easting_OSGR  Location_Northing_OSGR  \\\n",
      "0           0  200501BS00024               524700.0                180880.0   \n",
      "1           1  200501BS00032               524470.0                180980.0   \n",
      "2           2  200501BS70004               524870.0                181880.0   \n",
      "3           3  200501BS70009               525840.0                177020.0   \n",
      "4           4  200501BS70010               526940.0                177460.0   \n",
      "\n",
      "   Longitude   Latitude  Police_Force  Accident_Severity  Number_of_Vehicles  \\\n",
      "0  -0.204346  51.513039             1                  3                   2   \n",
      "1  -0.207623  51.513988             1                  3                   2   \n",
      "2  -0.201543  51.521988             1                  3                   2   \n",
      "3  -0.189301  51.478096             1                  3                   2   \n",
      "4  -0.173312  51.481804             1                  3                   2   \n",
      "\n",
      "   Number_of_Casualties  ... aadf_CLT_CBYPAS  aadf_CLT_BBYPAS aadf_CLT_PARKR  \\\n",
      "0                     1  ...            None             None           None   \n",
      "1                     1  ...            None             None           None   \n",
      "2                     1  ...           False            False          False   \n",
      "3                     1  ...           False            False          False   \n",
      "4                     1  ...           False            False          False   \n",
      "\n",
      "   aadf_CLT_WATERR aadf_CLT_PTIME  aadf_CLT_ACCESS  \\\n",
      "0             None           None              NaN   \n",
      "1             None           None              NaN   \n",
      "2            False          False              NaN   \n",
      "3            False          False              NaN   \n",
      "4            False          False              NaN   \n",
      "\n",
      "                                     aadf_CLT_COLOUR  \\\n",
      "0                                               None   \n",
      "1                                               None   \n",
      "2                                               [[]]   \n",
      "3  [['NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NON...   \n",
      "4                                         [['NONE']]   \n",
      "\n",
      "                                        aadf_BOROUGH  distance_to_cp  match  \n",
      "0                                               None             NaN  False  \n",
      "1                                               None             NaN  False  \n",
      "2                                               [[]]        0.154730   True  \n",
      "3  [[None, None, 'Hammersmith & Fulham', 'Hammers...        0.122721   True  \n",
      "4                         [['Kensington & Chelsea']]        0.012866   True  \n",
      "\n",
      "[5 rows x 99 columns]\n",
      "   Longitude   Latitude  Accident_Severity        Date   Time  in_london  \\\n",
      "0  -0.204346  51.513039                  3  2005-01-24  17:05       True   \n",
      "1  -0.207623  51.513988                  3  2005-01-30  20:00       True   \n",
      "2  -0.201543  51.521988                  3  2005-03-02  12:30       True   \n",
      "3  -0.189301  51.478096                  3  2005-03-02  17:30       True   \n",
      "4  -0.173312  51.481804                  3  2005-06-02  15:00       True   \n",
      "\n",
      "   fatal  serious  slight  \n",
      "0      0        0       1  \n",
      "1      0        0       1  \n",
      "2      0        0       1  \n",
      "3      0        0       1  \n",
      "4      0        0       1  \n",
      "2005-01-24 3 0 0 1\n",
      "2005-01-30 3 0 0 1\n",
      "2005-03-02 3 0 0 1\n",
      "2005-03-02 3 0 0 1\n",
      "2005-06-02 3 0 0 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Import pandas for data handling and analysis\n",
    "\n",
    "# Read the dataset from a Parquet file into a DataFrame\n",
    "pa_df = pd.read_parquet(\"combined_collisions_v3.parquet\")\n",
    "\n",
    "# Preview the first 5 rows of the DataFrame\n",
    "print(pa_df.head())\n",
    "\n",
    "# Select and display specific columns of interest: Longitude, Latitude, Accident Severity, Date, Time and whether the accident took place in London or not\n",
    "# Also deal with the outcomes: fatal, serious or slight\n",
    "print(pa_df[[\"Longitude\", \"Latitude\", \"Accident_Severity\", \"Date\", \"Time\", \"in_london\", \"fatal\", \"serious\", \"slight\"]].head())\n",
    "\n",
    "# Iterate through the first 5 rows of the DataFrame \n",
    "# Print out the Date, Accident Severity and the outcome (fatal, serious and slight)\n",
    "for _, row in pa_df.head(5).iterrows():\n",
    "    print(row[\"Date\"], row[\"Accident_Severity\"], row[\"fatal\"], row[\"serious\"], row[\"slight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "399a8e3e-d811-47ac-96e7-9e118974a4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Latitude: 49.91443\n",
      "Maximum Latitude: 60.344565\n",
      "Minimum Longitude: -7.504121\n",
      "Maximum Longitude: 1.76201\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Import pandas for data manipulation and analysis\n",
    "\n",
    "# Load the dataset from a Parquet file into a DataFrame\n",
    "pa_df = pd.read_parquet('combined_collisions_v3.parquet')\n",
    "\n",
    "# Calculate the minimum and maximum values for geographic coordinates\n",
    "minimum_latitude = pa_df['Latitude'].min()\n",
    "maximum_latitude = pa_df['Latitude'].max()\n",
    "minimum_longitude = pa_df['Longitude'].min()\n",
    "maximum_longitude = pa_df['Longitude'].max()\n",
    "\n",
    "# Print the results in a clear, labeled format\n",
    "print(f\"Minimum Latitude: {minimum_latitude}\")\n",
    "print(f\"Maximum Latitude: {maximum_latitude}\")\n",
    "print(f\"Minimum Longitude: {minimum_longitude}\")\n",
    "print(f\"Maximum Longitude: {maximum_longitude}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef10950-461e-47f4-a18d-c28f948681a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\bencr\\anaconda3\\lib\\site-packages (2.4.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\bencr\\anaconda3\\lib\\site-packages (from geopy) (2.1)\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80783187-2b47-4aed-ba6a-f4302801a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coordinates have been saved to london_boroughs_coordinates.parquet\n"
     ]
    }
   ],
   "source": [
    "import time # Import time to add pauses between API requests\n",
    "from geopy.geocoders import Nominatim # Import Nominatim geocoder from geopy\n",
    "import pandas as pd # Import pandas for data handling and export\n",
    "\n",
    "boroughs = [ # List of all London boroughs to geocode\n",
    "    \"Barking and Dagenham\", \"Barnet\", \"Bexley\", \"Brent\", \"Bromley\", \"Camden\", \"Croydon\", \n",
    "    \"Ealing\", \"Enfield\", \"Greenwich\", \"Hackney\", \"Hammersmith and Fulham\", \"Haringey\", \n",
    "    \"Harrow\", \"Havering\", \"Hillingdon\", \"Hounslow\", \"Islington\", \"Kensington and Chelsea\", \n",
    "    \"Kingston upon Thames\", \"Lambeth\", \"Lewisham\", \"Merton\", \"Newham\", \"Redbridge\", \n",
    "    \"Richmond upon Thames\", \"Southwark\", \"Sutton\", \"Tower Hamlets\", \"Waltham Forest\", \n",
    "    \"Wandsworth\", \"Westminster\", \"City of London\"\n",
    "]\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"london_boroughs_locator\") # Initialise the geolocator with a custom user agent for place identification\n",
    "borough_coordinates = {} # Dictionary to store borough names and their coordinates\n",
    "\n",
    "for b in boroughs: # Loop through each borough and attempt to geocode it\n",
    "    try:\n",
    "        location = geolocator.geocode(f\"{b}, London, UK\", timeout=10) # Query Nominatim for the borough location (timeout to prevent server crashing)\n",
    "        if location: # If a location is found, store latitude and longitude \n",
    "            borough_coordinates[b] = (location.latitude, location.longitude)\n",
    "        else: # If not found, store None placeholders\n",
    "            borough_coordinates[b] = (None, None)\n",
    "    except Exception as e: # Handle errors gracefully and log the borough that failed\n",
    "        print(f\"Error with {b}: {e}\") \n",
    "        borough_coordinates[b] = (None, None)\n",
    "    \n",
    "    time.sleep(1) # Pause for 1 second between requests to respect Nominatimâ€™s usage policy\n",
    "\n",
    "lb_df = pd.DataFrame(borough_coordinates.items(), columns=['Borough', 'Coordinates']) # Convert the dictionary into a DataFrame\n",
    "lb_df[['Latitude', 'Longitude']] = pd.DataFrame(lb_df['Coordinates'].tolist(), index=lb_df.index) # Split the tuple in 'Coordinates' into separate Latitude and Longitude columns\n",
    "lb_df.drop(columns=['Coordinates'], inplace=True) # Drop the original 'Coordinates' column \n",
    "\n",
    "lb_df.to_parquet(\"london_boroughs_coordinates.parquet\", index=False) # Save the DataFrame to a Parquet file for efficient storage and reproducibility\n",
    "print(\"The coordinates have been saved to london_boroughs_coordinates.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c059c75f-3a96-4f07-9a7f-0ff920effead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Latitude: 51.3574645\n",
      "Maximum Latitude: 51.65309\n",
      "Minimum Longitude: -0.4483349\n",
      "Maximum Longitude: 0.2498128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from a Parquet file into a DataFrame\n",
    "df = pd.read_parquet('london_boroughs_coordinates.parquet')\n",
    "\n",
    "# Compute the minimum and maximum values for latitude and longitude based on the boroughs\n",
    "minimum_latitude = df['Latitude'].min()\n",
    "maximum_latitude = df['Latitude'].max()\n",
    "minimum_longitude = df['Longitude'].min()\n",
    "maximum_longitude = df['Longitude'].max()\n",
    "\n",
    "print(f\"Minimum Latitude: {minimum_latitude}\")\n",
    "print(f\"Maximum Latitude: {maximum_latitude}\")\n",
    "print(f\"Minimum Longitude: {minimum_longitude}\")\n",
    "print(f\"Maximum Longitude: {maximum_longitude}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eb508a4-4596-481c-a36c-6fc8939db4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\bencr\\anaconda3\\lib\\site-packages (25.1)\n",
      "Collecting pip\n",
      "  Using cached pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.1\n",
      "    Uninstalling pip-25.1:\n",
      "      Successfully uninstalled pip-25.1\n",
      "Successfully installed pip-25.3\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
